---
title: '服務概觀'
sidebar_label: '服務概觀'
sidebar_position: 1
sync_original_production: 'https://man.twcc.ai/@twccdocs/ccs-overview-en' 
sync_original_preview: 'https://man.twcc.ai/@preview-twccdocs/ccs-overview-en' 
---


# ![-](https://cos.twcc.ai/SYS-MANUAL/uploads/upload_0b81080da8a39866cd1e0aa0471e9552.png) Service overview
<!-- <img style={{width:25+'px', height:25+'px'}} src='https://cos.twcc.ai/SYS-MANUAL/uploads/upload_0b81080da8a39866cd1e0aa0471e9552.png' />  -->


## Container Compute Service provides rapid deployment of GPU working environment and improves work efficiency!

Interactive Container enables you to deploy development environment quickly, choose different AI frameworks on demand, and edit script directly through the built-in Jupyter Notebook. Container service is mounted with Hyper File System (HFS) automatically. Also, users can use Cloud Object Storage(COS) in containers by themselves to store training data and models.


### ![-](https://cos.twcc.ai/SYS-MANUAL/uploads/upload_9031b03afa1291f2d95f9dbc60cf2948.png) Use the service with ease 


Container service may be established through the TWCC portal, API, or CLI (Command Line Interface). Contrasting with traditional supercomputers, whose resources are available to users only through CLI, TWCC allows you the freedom to choose the interface that you are familiar with to easily stack applications.

<!-- <img style={{width:35+'px', height:25+'px'}} src='https://cos.twcc.ai/SYS-MANUAL/uploads/upload_9031b03afa1291f2d95f9dbc60cf2948.png'/>  -->


### ![-](https://cos.twcc.ai/SYS-MANUAL/uploads/upload_afd344f9a1b3d0567f83a250da8b8d26.png) Rapidly deploy a working environment

Use Kubernetes open-source framework and optimized Nvidia AI software stack and utilize world-connecting virtual technology to quickly deploy a work environment. This presents the time decrease by 3 times over the traditional approach, and this also allows users the flexibility to switch platforms.

<!-- <img style={{width:35+'px', height:25+'px'}} src='https://cos.twcc.ai/SYS-MANUAL/uploads/upload_afd344f9a1b3d0567f83a250da8b8d26.png'/>  -->


### ![-](https://cos.twcc.ai/SYS-MANUAL/uploads/upload_d404fdf4e28033ae3c6185c87888ab51.png) Diverse AI frameworks

TWCC provides Nvidia-optimized AI frameworks such as TensorFlow, Caffe, CUDA, Torch, PyTorch, TensorRT, TensorRT Server, CNTK, MXNet, Theano, DIGITS and RAPIDS to users so they don’t need to worry about the installation. This also satisfies the demands of different model training and inference.

<!-- <img style={{width:35+'px', height:25+'px'}} src='https://cos.twcc.ai/SYS-MANUAL/uploads/upload_d404fdf4e28033ae3c6185c87888ab51.png'/> -->


### ![-](https://cos.twcc.ai/SYS-MANUAL/uploads/upload_cb712cc256270388197b36fdb9757d68.png)Different container options

- Interactive containers coupled with Jupyter Notebook editor for programs enable online debugging and computation. Work can be completed even with mobile devices so that you always have a firm grasp of the progress of your project.
- Scheduled containers allow the designation of job starting time. Properly plan and schedule the amount of resources by batches can improve work efficiency. Once the computations are completed, computing resources are taken back, effectively saving the costs of development.

<!-- <img style={{width:35+'px', height:25+'px'}} src='https://cos.twcc.ai/SYS-MANUAL/uploads/upload_cb712cc256270388197b36fdb9757d68.png'/>  -->


### ![-](https://cos.twcc.ai/SYS-MANUAL/uploads/upload_22d79d4fc2df0425c3f9c9e1e0591396.png) Safe and fast storage system

TWCC provides Hyper File System to accelerate computations. You may also use Cloud Object Storage. Your data can be stored safely so you don’t need to worry about losing them.

<!-- <img style={{width:35+'px', height:25+'px'}} src='https://cos.twcc.ai/SYS-MANUAL/uploads/upload_22d79d4fc2df0425c3f9c9e1e0591396.png'/>  -->


### ![-](https://cos.twcc.ai/SYS-MANUAL/uploads/upload_b5b69c51d21e91a714e4152465fed59e.png) Many bottom-layer benefits


- Network structured for tenant isolation makes it safe to use.
- Functions are constantly optimized with Kubernetes rolling updates.
- With Kubernetes and HPC hyper-converged infrastructure (HCI) , GPU containers for application development have the capability to allocate resources in HPC for parallel computing.

<!-- <img style={{width:35+'px', height:25+'px'}} src='https://cos.twcc.ai/SYS-MANUAL/uploads/upload_b5b69c51d21e91a714e4152465fed59e.png'/>  -->