---
sidebar_label: 'Merlin Inference'
sidebar_position: 19
title: 'Merlin Inference'
sync_original_production: 'https://man.twcc.ai/@twccdocs/ccs-concept-image-merlin-inference-en'
sync_original_preview: 'https://man.twcc.ai/@preview-twccdocs/ccs-concept-image-merlin-inference-en'
---


# <img style={{width:55+'px'}} src='https://cos.twcc.ai/SYS-MANUAL/uploads/upload_3022d6e6790c870e499eac8e2c77d53c.png' /> Merlin Inference

TWCC provides pay-as-you-go working environment of NGC Merlin Inference container. It is a framework for accelerating the entire recommender systems pipeline on the GPU: from data ingestion and training to deployment. Merlin empowers data scientists, machine learning engineers, and researchers to build high-performing recommenders at scale. Merlin includes tools that democratize building deep learning recommenders by addressing common ETL, training, and inference challenges.

## <i class="fa fa-sticky-note" aria-hidden="true"></i> <span class="ccsimglist">Information of Image file version</span> 

![](https://cos.twcc.ai/SYS-MANUAL/uploads/upload_5359dea294a635a9a9985b1d9d843ee1.png)




<details class="docspoiler">

<summary><b>Detailed package version information</b></summary>

- [NGC Merlin Inference](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-inference) 

</details>



